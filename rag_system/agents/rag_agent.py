from tools.retriever import Retriever
from tools.Judge import Judge
from tools.reformulator import Reformulator
from tools.answer_generator import AnswerGenerator
from models.generator import Generator
from models.vectorizer import Vectorizer


class RAGAgent:
    def __init__(self, vectorizer: Vectorizer, generator: Generator):
        self.retriever = Retriever(vectorizer)
        self.judge = Judge(generator)
        self.reformulator = Reformulator(generator)
        self.answer_generator = AnswerGenerator(generator)
        self.generator = generator

    async def answer(self, question: str, stream: bool = True):
        """
        Pipeline RAG LLM-based.
        - Notifie "R√©flexion en cours" (enable_thinking).
        - Si pas besoin de recherche ‚Üí r√©ponse directe.
        - Sinon ‚Üí recherche + jugement + (jusqu'√† 3) reformulations.
        - Si rien de pertinent ‚Üí propose reformulation + r√©ponse provisoire, sans hors-sujet.
        """
        # === 0) notifier r√©flexion (thinking) ===
        yield "ü§î R√©flexion en cours...\n"

        # === 1) d√©cision : faut-il rechercher ? ===
        need_retrieval = self._ask_need_retrieval(question)

        # === Cas A : Pas besoin de recherche ‚Üí r√©ponse directe ===
        if not need_retrieval:
            if stream:
                async for token in self.generator.stream_generate(question):
                    yield token
            else:
                yield self.generator.simple_answer(question)
            return

        # === Cas B : Recherche documentaire ===
        yield "üìö Recherche en cours...\n"

        current_q = question
        last_docs = []  # garder les derniers documents r√©cup√©r√©s (fallback)
        for step in range(3):  # max 3 reformulations
            docs = self.retriever.search(current_q)
            last_docs = docs

            verdict = self.judge.evaluate(current_q, docs)
            # Logs serveurs utiles
            print(f"[RAG] √âtape {step+1} ‚Äî question: {current_q}")
            print(f"[RAG] Docs r√©cup√©r√©s: {len(docs)} | Verdict: {verdict}")

            if verdict == "PERTINENT":
                # G√©n√©ration finale (stream√©e)
                if stream:
                    async for token in self.answer_generator.stream_answer(current_q, docs):
                        yield token
                else:
                    yield self.answer_generator.simple_answer(current_q, docs)
                return
            else:
                # Reformuler et r√©essayer
                current_q = self.reformulator.reformulate(current_q, docs)

        # === Cas C : Rien de parfaitement pertinent apr√®s 3 tentatives ===
        # Politique : ne jamais faire de hors-sujet. On propose reformulation + r√©ponse prudente.
        if last_docs:
            # 1) informer l‚Äôutilisateur
            yield (
                "\n‚ö†Ô∏è Je n‚Äôai pas trouv√© de disposition correspondant exactement √† votre demande. "
                "Pouvez-vous reformuler votre question de fa√ßon plus pr√©cise (ex. type de soci√©t√©, r√¥le : associ√©/g√©rant, "
                "contexte : cumul d‚Äôactivit√©s, conflit d‚Äôint√©r√™ts, etc.) ?\n"
                "‚Ü≥ En attendant, voici des √©l√©ments susceptibles d‚Äô√©clairer le sujet :\n\n"
            )

            # 2) r√©ponse provisoire strictement bas√©e sur les extraits les plus proches
            fallback_prompt = (
                "Tu es un assistant sp√©cialis√© dans la Fonction publique du S√©n√©gal. "
                "Les extraits ci-dessous peuvent √™tre li√©s au sujet mais ne r√©pondent pas exactement √† la question. "
                "Fais une r√©ponse prudente et partielle STRICTEMENT bas√©e sur ces extraits, sans inventer, "
                "et sans sortir du domaine de la fonction publique. "
                "Si l‚Äôinformation manque, dis-le clairement et sugg√®re une reformulation pr√©cise.\n\n"
                f"Question initiale : {question}\n\n"
                "Extraits (ne cite que s‚Äôils sont pertinents, sinon dis que l‚Äôinfo manque) :\n"
                + "\n".join(f"- {d['text'][:400]}..." for d in last_docs[:3])
                + "\n\nR√©ponse provisoire :"
            )

            if stream:
                async for token in self.generator.stream_generate(fallback_prompt):
                    yield token
            else:
                yield self.generator.simple_answer(fallback_prompt)
        else:
            # Aucun doc exploitable du tout
            yield (
                "‚ö†Ô∏è Je n‚Äôai trouv√© aucun extrait exploitable. "
                "Pouvez-vous reformuler votre question (ex. type de soci√©t√©, r√¥le envisag√©, cadre exact) ?"
            )

    # === D√©cide si une recherche documentaire est n√©cessaire ===
    def _ask_need_retrieval(self, question: str) -> bool:
        prompt = f"""
Tu es un assistant **sp√©cialis√© dans la Fonction publique s√©n√©galaise**. 
Tu r√©ponds uniquement sur des questions juridiques, administratives et r√©glementaires du S√©n√©gal.

La question suivante n√©cessite-t-elle de consulter des documents juridiques/administratifs 
(PDFs, d√©crets, lois, statuts s√©n√©galais) pour r√©pondre correctement ?

Question: "{question}"

R√©ponds UNIQUEMENT par "OUI" ou "NON".
"""
        response = self.generator.simple_answer(prompt, max_new_tokens=3)
        return response.strip().upper().startswith("OUI")
