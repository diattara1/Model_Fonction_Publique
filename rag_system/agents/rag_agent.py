# agents/rag_agent.py
from tools.retriever import Retriever
from tools.Judge import Judge
from tools.reformulator import Reformulator
from tools.answer_generator import AnswerGenerator
from models.generator import Generator
from models.vectorizer import Vectorizer


class RAGAgent:
    def __init__(self, vectorizer: Vectorizer, generator: Generator):
        self.retriever = Retriever(vectorizer)
        self.judge = Judge(generator)
        self.reformulator = Reformulator(generator)
        self.answer_generator = AnswerGenerator(generator)
        self.generator = generator

    async def answer(self, question: str, stream: bool = True):
        """
        Pipeline RAG LLM-based:
        - Si pas besoin de recherche ‚Üí r√©ponse directe (multi-tour)
        - Sinon ‚Üí recherche + jugement + √©ventuelles reformulations
        - Fallback: proposer reformulation utilisateur + r√©ponse provisoire
        """
        # üëâ notifier le front que le mod√®le r√©fl√©chit
        yield "ü§î R√©flexion en cours‚Ä¶"

        need_retrieval = self._ask_need_retrieval(question)

        # === Cas 1 : Pas besoin de recherche ===
        if not need_retrieval:
            if stream:
                # ‚úÖ utilise la m√©moire multi-tour
                async for token in self.generator.stream_generate_mt(question):
                    yield token
            else:
                yield self.generator.simple_answer_mt(question)
            return

        # === Cas 2 : Recherche documentaire ===
        yield "üìö Recherche en cours..."
        current_q = question
        last_docs = []

        for step in range(3):  # max 3 reformulations
            docs = self.retriever.search(current_q)
            last_docs = docs
            verdict = self.judge.evaluate(current_q, docs)
            print("reformulation n:", step, " : ", current_q, " doc r√©cup√©r√©s :", docs)

            if verdict == "PERTINENT":
                # ‚úÖ r√©ponse finale RAG avec m√©moire
                async for token in self.answer_generator.stream_answer(
                    current_q, docs, use_history=True
                ):
                    yield token
                return
            else:
                current_q = self.reformulator.reformulate(current_q, docs)

        # === Cas 3 : Rien de parfaitement pertinent ===
        if last_docs:
            fallback_prompt = f"""
La question pos√©e est : "{question}".

Les extraits trouv√©s ne r√©pondent pas exactement, mais peuvent √™tre li√©s.
Donne une r√©ponse prudente et partielle bas√©e uniquement sur ces extraits, 
sans inventer ni sortir du domaine de la fonction publique.
Termine par : "‚ö†Ô∏è Je n‚Äôai pas trouv√© de r√©ponse parfaitement adapt√©e. Pouvez-vous reformuler votre question de fa√ßon plus pr√©cise ?"

Extraits:
{chr(10).join(f"- {d['text'][:400]}..." for d in last_docs[:3])}

R√©ponse provisoire:
"""
            if stream:
                async for token in self.generator.stream_generate_mt(fallback_prompt):
                    yield token
            else:
                yield self.generator.simple_answer_mt(fallback_prompt)
            return

        # === Cas 4 : Rien trouv√© du tout ===
        yield "‚ö†Ô∏è Je n‚Äôai rien trouv√© de pertinent. Pouvez-vous pr√©ciser votre question ?"

    def _ask_need_retrieval(self, question: str) -> bool:
        """
        Demande au LLM si une recherche documentaire est n√©cessaire
        pour r√©pondre correctement.
        """
        prompt = f"""
Tu es un assistant **sp√©cialis√© dans la Fonction publique s√©n√©galaise**. 
Ton r√¥le est d‚Äôaider uniquement sur les questions juridiques, administratives et r√©glementaires li√©es √† la fonction publique du S√©n√©gal.

La question suivante n√©cessite-t-elle de consulter des documents juridiques/administratifs 
(pdfs, d√©crets, lois, statuts s√©n√©galais) pour r√©pondre correctement ?

Question: "{question}"

R√©ponds UNIQUEMENT par "OUI" ou "NON".
"""
        response = self.generator.simple_answer(prompt, max_new_tokens=3)
        return response.strip().upper().startswith("OUI")
